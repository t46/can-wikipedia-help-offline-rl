{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Activation and Data Used for Getting the Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from sample_batch_data import get_data_info, get_batch\n",
    "from signal_propagation import get_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_and_activation(\n",
    "    path_to_load_dataset,\n",
    "    path_to_save_d4rl_data_sample,\n",
    "    path_to_save_activation,\n",
    "    seed=666,\n",
    "    model_name='gpt2',\n",
    "    epoch=40,\n",
    "    env_name_list=['hopper', 'halfcheetah', 'walker2d'],\n",
    "    ):\n",
    "    \"\"\"Save activation and associated data.\n",
    "\n",
    "    Args:\n",
    "        path_to_save_d4rl_data_sample (str): Path to save a batch of sampled D4RL data.\n",
    "        path_to_save_activation (str): Path to save a batch of activations of neural networks.\n",
    "        seed (int, optional): random seed. Defaults to 666.\n",
    "        model_name (str, optional): 'gpt2', 'igpt', or 'dt'. Defaults to 'gpt2'.\n",
    "        epoch (int, optional): 0 or 40. Defaults to 40.\n",
    "        env_name_list (list, optional): environment name list. Defaults to ['hopper', 'halfcheetah', 'walker2d'].\n",
    "    \"\"\"    \n",
    "\n",
    "    for env_name in env_name_list:\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        dataset_name = 'medium'\n",
    "\n",
    "        if model_name == 'gpt2':\n",
    "            pretrained_lm1 = 'gpt2'\n",
    "        elif model_name == 'clip':\n",
    "            pretrained_lm1 = 'openai/clip-vit-base-patch32'\n",
    "        elif model_name == 'igpt':\n",
    "            pretrained_lm1 = 'openai/imagegpt-small'\n",
    "        elif model_name == 'dt':\n",
    "            pretrained_lm1 = False\n",
    "\n",
    "        variant = {\n",
    "            'embed_dim': 768,\n",
    "            'n_layer': 12,\n",
    "            'n_head': 1,\n",
    "            'activation_function': 'relu',\n",
    "            'dropout': 0.2, # 0.1\n",
    "            'load_checkpoint': False if epoch==0 else f'../checkpoints/{model_name}_medium_{env_name}_666/model_{epoch}.pt',\n",
    "            'seed': seed,\n",
    "            'outdir': f\"checkpoints/{model_name}_{dataset_name}_{env_name}_{seed}\",\n",
    "            'env': env_name,\n",
    "            'dataset': dataset_name,\n",
    "            'model_type': 'dt',\n",
    "            'K': 20, # 2\n",
    "            'pct_traj': 1.0,\n",
    "            'batch_size': 100,  # 64\n",
    "            'num_eval_episodes': 100,\n",
    "            'max_iters': 40,\n",
    "            'num_steps_per_iter': 2500,\n",
    "            'pretrained_lm': pretrained_lm1,\n",
    "            'gpt_kmeans': None,\n",
    "            'kmeans_cache': None,\n",
    "            'frozen': False,\n",
    "            'extend_positions': False,\n",
    "            'share_input_output_proj': True\n",
    "        }\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        state_dim, act_dim, max_ep_len, scale = get_data_info(variant)\n",
    "        states, actions, rewards, dones, rtg, timesteps, attention_mask = get_batch(variant, state_dim, act_dim, max_ep_len, scale, device, path_to_load_dataset)\n",
    "\n",
    "        data = {\n",
    "            'states': states,\n",
    "            'actions': actions,\n",
    "            'rtg': rtg,\n",
    "            'timesteps': timesteps,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "        activation = get_activation(variant, state_dim, act_dim, max_ep_len, states, actions, rewards, rtg, timesteps, attention_mask)\n",
    "        batch_size = variant['batch_size']\n",
    "        np.save(f'{path_to_save_activation}/activation_{epoch}_{model_name}_{env_name}_{dataset_name}_{seed}_{batch_size}.npy', activation)\n",
    "        np.save(f'{path_to_save_d4rl_data_sample}/data_{env_name}_{dataset_name}_{seed}_{batch_size}.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_load_dataset = 'path_to_load_dataset'  # path to dataset to load from\n",
    "'''\n",
    "Following paths are used in .../mine-pytorch/run_mi.py (,run_mi_no_context.py, and run_mi_data.py)\n",
    "'''\n",
    "path_to_save_d4rl_data_sample = 'path_to_save_d4rl_data_sample'\n",
    "path_to_save_activation = 'path_to_save_activation'\n",
    "save_data_and_activation(\n",
    "    path_to_load_dataset,\n",
    "    path_to_save_d4rl_data_sample,\n",
    "    path_to_save_activation,\n",
    "    seed=666,\n",
    "    model_name='gpt2',\n",
    "    epoch=40,\n",
    "    env_name_list=['hopper'],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('transformer_genralization')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e69258a44f8e7625f8a17da91770617d51f6311f8535e6184b95ec1daa3f2df5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
