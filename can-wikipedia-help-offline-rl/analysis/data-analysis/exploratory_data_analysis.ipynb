{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import d4rl # Import required to register environments\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"halfcheetah-medium-v2\"\n",
    "env = gym.make(name)\n",
    "dataset = env.get_dataset()\n",
    "rewards = dataset['rewards']\n",
    "actions = dataset['actions']\n",
    "observations = dataset['observations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(actions.shape[1]):\n",
    "    plt.hist(actions[:, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into that with large reward and that with small reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_set = np.array([rewards[i * 1000: (i + 1) * 1000] for i in range(len(rewards) // 1000)])\n",
    "trajectory_mean = trajectory_set.mean(axis=0)\n",
    "trajectory_std = trajectory_set.std(axis=0)\n",
    "\n",
    "x = np.arange(len(rewards) // 1000)\n",
    "trajectory_lower = trajectory_mean - trajectory_std\n",
    "trajectory_upper = trajectory_mean + trajectory_std\n",
    "\n",
    "plt.plot(trajectory_mean)\n",
    "plt.fill_between(x, trajectory_lower, trajectory_upper, alpha=0.3)\n",
    "plt.vlines(x=100, ymin=min(trajectory_lower) - 1, ymax=max(trajectory_upper) + 1, label='step 100')\n",
    "plt.ylim(min(trajectory_lower) - 1, max(trajectory_upper) + 1)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Step')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 5000\n",
    "threshold = 100\n",
    "X = observations[:max_length, :]\n",
    "labels = []\n",
    "for step in range(max_length):\n",
    "    offset = step % 1000\n",
    "    if step % 1000 < threshold:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=41)\n",
    "X_reduced = tsne.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1],\n",
    "            c=labels, cmap='jet',\n",
    "            s=15, alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot as 1-Dimensional Time Seriese Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality_reduction = 'pca'\n",
    "\n",
    "if dimensionality_reduction == 'pca':\n",
    "    action_feature = PCA(n_components=1).fit(actions).transform(actions)\n",
    "    state_feature = PCA(n_components=1).fit(observations).transform(observations)\n",
    "elif dimensionality_reduction == 'kmeans':\n",
    "    action_feature = KMeans(n_clusters=10).fit(actions).fit_predict(actions)\n",
    "    state_feature = KMeans(n_clusters=10).fit(observations).fit_predict(observations)\n",
    "else:\n",
    "    print('no such feature')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(np.arange(len(rewards[:10000])), rewards[:10000])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07f70ea1113ee523b3efee6307f7578bdf4830bd47c6db9199b4b48d8758cb04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('wikirl-gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
