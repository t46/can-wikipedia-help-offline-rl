{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad0d61-8dd3-426a-b71a-bab85f00d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/shiro/research/projects/rl-nlp/can-wikipedia-help-offline-rl/code')\n",
    "\n",
    "from decision_transformer.evaluation.evaluate_episodes import (\n",
    "    evaluate_episode,\n",
    "    evaluate_episode_rtg,\n",
    ")\n",
    "from decision_transformer.models.decision_transformer import DecisionTransformer\n",
    "from decision_transformer.models.mlp_bc import MLPBCModel\n",
    "from decision_transformer.training.act_trainer import ActTrainer\n",
    "from decision_transformer.training.seq_trainer import SequenceTrainer\n",
    "\n",
    "from utils import get_optimizer\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0203f30d-1aad-4aa8-b931-73c0aebb0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cumsum(x, gamma):\n",
    "    discount_cumsum = np.zeros_like(x)\n",
    "    discount_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0] - 1)):\n",
    "        discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "    return discount_cumsum\n",
    "\n",
    "def prepare_data(variant):\n",
    "    env_name, dataset = variant[\"env\"], variant[\"dataset\"]\n",
    "    model_type = variant[\"model_type\"]\n",
    "    exp_prefix = 'gym-experiment'\n",
    "    group_name = f\"{exp_prefix}-{env_name}-{dataset}\"\n",
    "    exp_prefix = f\"{group_name}-{random.randint(int(1e5), int(1e6) - 1)}\"\n",
    "\n",
    "    if env_name == \"hopper\":\n",
    "        env = gym.make(\"Hopper-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [3600, 1800]  # evaluation conditioning targets\n",
    "        scale = 1000.0  # normalization for rewards/returns\n",
    "    elif env_name == \"halfcheetah\":\n",
    "        env = gym.make(\"HalfCheetah-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [12000, 6000]\n",
    "        scale = 1000.0\n",
    "    elif env_name == \"walker2d\":\n",
    "        env = gym.make(\"Walker2d-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [5000, 2500]\n",
    "        scale = 1000.0\n",
    "    elif env_name == \"reacher2d\":\n",
    "        from decision_transformer.envs.reacher_2d import Reacher2dEnv\n",
    "\n",
    "        env = Reacher2dEnv()\n",
    "        max_ep_len = 100\n",
    "        env_targets = [76, 40]\n",
    "        scale = 10.0\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if model_type == \"bc\":\n",
    "        env_targets = env_targets[\n",
    "            :1\n",
    "        ]  # since BC ignores target, no need for different evaluations\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    # load dataset\n",
    "    dataset_path = f\"../data/{env_name}-{dataset}-v2.pkl\"\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        trajectories = pickle.load(f)\n",
    "\n",
    "    # save all path information into separate lists\n",
    "    mode = variant.get(\"mode\", \"normal\")\n",
    "    states, traj_lens, returns = [], [], []\n",
    "    for path in trajectories:\n",
    "        if mode == \"delayed\":  # delayed: all rewards moved to end of trajectory\n",
    "            path[\"rewards\"][-1] = path[\"rewards\"].sum()\n",
    "            path[\"rewards\"][:-1] = 0.0\n",
    "        states.append(path[\"observations\"])\n",
    "        traj_lens.append(len(path[\"observations\"]))\n",
    "        returns.append(path[\"rewards\"].sum())\n",
    "    traj_lens, returns = np.array(traj_lens), np.array(returns)\n",
    "\n",
    "    # used for input normalization\n",
    "    states = np.concatenate(states, axis=0)\n",
    "    state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "    num_timesteps = sum(traj_lens)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Starting new experiment: {env_name} {dataset}\")\n",
    "    print(f\"{len(traj_lens)} trajectories, {num_timesteps} timesteps found\")\n",
    "    print(f\"Average return: {np.mean(returns):.2f}, std: {np.std(returns):.2f}\")\n",
    "    print(f\"Max return: {np.max(returns):.2f}, min: {np.min(returns):.2f}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    pct_traj = variant.get(\"pct_traj\", 1.0)\n",
    "\n",
    "    # only train on top pct_traj trajectories (for %BC experiment)\n",
    "    num_timesteps = max(int(pct_traj * num_timesteps), 1)\n",
    "    sorted_inds = np.argsort(returns)  # lowest to highest\n",
    "    num_trajectories = 1\n",
    "    timesteps = traj_lens[sorted_inds[-1]]\n",
    "    ind = len(trajectories) - 2\n",
    "    while ind >= 0 and timesteps + traj_lens[sorted_inds[ind]] < num_timesteps:\n",
    "        timesteps += traj_lens[sorted_inds[ind]]\n",
    "        num_trajectories += 1\n",
    "        ind -= 1\n",
    "    sorted_inds = sorted_inds[-num_trajectories:]\n",
    "\n",
    "    # used to reweight sampling so we sample according to timesteps instead of trajectories\n",
    "    p_sample = traj_lens[sorted_inds] / sum(traj_lens[sorted_inds])\n",
    "    \n",
    "    return trajectories, sorted_inds, state_dim, act_dim, max_ep_len, state_mean, state_std, num_trajectories, p_sample, scale\n",
    "\n",
    "def get_batch(\n",
    "    batch_size, \n",
    "    max_len,\n",
    "    trajectories,\n",
    "    sorted_inds,\n",
    "    state_dim,\n",
    "    act_dim,\n",
    "    max_ep_len,\n",
    "    state_mean,\n",
    "    state_std,\n",
    "    num_trajectories,\n",
    "    p_sample,\n",
    "    scale,\n",
    "    device\n",
    "    ):\n",
    "    batch_inds = np.random.choice(\n",
    "        np.arange(num_trajectories),\n",
    "        size=batch_size,\n",
    "        replace=True,\n",
    "        p=p_sample,  # reweights so we sample according to timesteps\n",
    "    )\n",
    "\n",
    "    s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "    for i in range(batch_size):\n",
    "        traj = trajectories[int(sorted_inds[batch_inds[i]])]\n",
    "        si = random.randint(0, traj[\"rewards\"].shape[0] - 1)\n",
    "\n",
    "        # get sequences from dataset\n",
    "        s.append(traj[\"observations\"][si : si + max_len].reshape(1, -1, state_dim))\n",
    "        a.append(traj[\"actions\"][si : si + max_len].reshape(1, -1, act_dim))\n",
    "        r.append(traj[\"rewards\"][si : si + max_len].reshape(1, -1, 1))\n",
    "        if \"terminals\" in traj:\n",
    "            d.append(traj[\"terminals\"][si : si + max_len].reshape(1, -1))\n",
    "        else:\n",
    "            d.append(traj[\"dones\"][si : si + max_len].reshape(1, -1))\n",
    "        timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "        timesteps[-1][timesteps[-1] >= max_ep_len] = (\n",
    "            max_ep_len - 1\n",
    "        )  # padding cutoff\n",
    "        rtg.append(\n",
    "            discount_cumsum(traj[\"rewards\"][si:], gamma=1.0)[\n",
    "                : s[-1].shape[1] + 1\n",
    "            ].reshape(1, -1, 1)\n",
    "        )\n",
    "        if rtg[-1].shape[1] <= s[-1].shape[1]:\n",
    "            rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "        # padding and state + reward normalization\n",
    "        tlen = s[-1].shape[1]\n",
    "        s[-1] = np.concatenate(\n",
    "            [np.zeros((1, max_len - tlen, state_dim)), s[-1]], axis=1\n",
    "        )\n",
    "        s[-1] = (s[-1] - state_mean) / state_std\n",
    "        a[-1] = np.concatenate(\n",
    "            [np.ones((1, max_len - tlen, act_dim)) * -10.0, a[-1]], axis=1\n",
    "        )\n",
    "        r[-1] = np.concatenate([np.zeros((1, max_len - tlen, 1)), r[-1]], axis=1)\n",
    "        d[-1] = np.concatenate([np.ones((1, max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "        rtg[-1] = (\n",
    "            np.concatenate([np.zeros((1, max_len - tlen, 1)), rtg[-1]], axis=1)\n",
    "            / scale\n",
    "        )\n",
    "        timesteps[-1] = np.concatenate(\n",
    "            [np.zeros((1, max_len - tlen)), timesteps[-1]], axis=1\n",
    "        )\n",
    "        mask.append(\n",
    "            np.concatenate(\n",
    "                [np.zeros((1, max_len - tlen)), np.ones((1, tlen))], axis=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    s = torch.from_numpy(np.concatenate(s, axis=0)).to(\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    a = torch.from_numpy(np.concatenate(a, axis=0)).to(\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    r = torch.from_numpy(np.concatenate(r, axis=0)).to(\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    d = torch.from_numpy(np.concatenate(d, axis=0)).to(\n",
    "        dtype=torch.long, device=device\n",
    "    )\n",
    "    rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).to(\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).to(\n",
    "        dtype=torch.long, device=device\n",
    "    )\n",
    "    mask = torch.from_numpy(np.concatenate(mask, axis=0)).to(device=device)\n",
    "\n",
    "    return s, a, r, d, rtg, timesteps, mask\n",
    "\n",
    "def compute_cka(activation_1, activation_2, reward_state_action, timestep=-1):\n",
    "\n",
    "    if reward_state_action == 'reward':\n",
    "        idx = timestep * 3\n",
    "    elif reward_state_action == 'state':\n",
    "        idx = timestep * 2\n",
    "    elif reward_state_action == 'action':\n",
    "        idx = timestep * 1\n",
    "    else:\n",
    "        print(\"Specify either 'reward', 'state', or 'action'.\")\n",
    "\n",
    "    # activationの次元（activation_1.shape[1]）とcontextの次元（activation_1.shape[2]）を同一次元に潰す\n",
    "    if len(activation_1.shape) == 3:\n",
    "        activation_1 = activation_1[:, :, idx]\n",
    "    elif len(activation_1.shape) == 4:\n",
    "        activation_1 = activation_1[:, :, idx, idx]\n",
    "    if len(activation_2.shape) == 3:\n",
    "        activation_2 = activation_2[:, :, idx]\n",
    "    elif len(activation_2.shape) == 4:\n",
    "        activation_2 = activation_2[:, :, idx, idx]\n",
    "\n",
    "    # Center\n",
    "    X = activation_1 - activation_1.mean(0, keepdim=True)\n",
    "    Y = activation_2 - activation_2.mean(0, keepdim=True)\n",
    "\n",
    "    XtX_F = torch.norm(torch.mm(X.t(), X), p='fro').item()\n",
    "    YtY_F = torch.norm(torch.mm(Y.t(), Y), p='fro').item()\n",
    "    YtX_F = torch.norm(torch.mm(Y.t(), X), p='fro').item()\n",
    "\n",
    "    # eq 5 in paper\n",
    "    cka = YtX_F**2 / (XtX_F*YtY_F)\n",
    "\n",
    "    return cka\n",
    "\n",
    "def plot_cka(cka_matrix, reward_state_action, model1, model2, env_name, dataset_name, seed, epoch1, epoch2):\n",
    "    \n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 2})\n",
    "\n",
    "    ax = sns.heatmap(cka_matrix, vmin=0, vmax=1)  # , cmap='bone'\n",
    "    ax.axis('equal')\n",
    "    plt.ylim(0, len(cka_matrix))\n",
    "    plt.xlim(0, len(cka_matrix))\n",
    "    plt.xlabel(f'{model1.upper()} Layers at Epoch {epoch1}')\n",
    "    plt.ylabel(f'{model2.upper()} Layers at Epoch {epoch2}')\n",
    "    plt.title(f'CKA: {model1.upper()} ' + r'$\\times$' + f' {model1.upper()}, ' + f'{reward_state_action.upper()}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figs/cka_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.diag(cka_matrix), color=(0.372, 0.537, 0.537))\n",
    "    plt.scatter(np.arange(len(np.diag(cka_matrix))), np.diag(cka_matrix), color=(0.372, 0.537, 0.537))\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('CKA')\n",
    "    plt.title(f'CKA per Layer: {reward_state_action.upper()}')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figs/cka_plot_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "154c9144-2646-4eb7-ab47-d1a3ae6e1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cka(\n",
    "    seed=666,\n",
    "    model1='gpt2',\n",
    "    model2='gpt2',\n",
    "    epoch1=40,\n",
    "    epoch2=40,\n",
    "    env_name_list=['hopper', 'halfcheetah', 'walker2d'],\n",
    "    ):\n",
    "\n",
    "    for env_name in env_name_list:\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        dataset_name = 'medium'\n",
    "\n",
    "        if model1 == 'gpt2':\n",
    "            pretrained_lm1 = 'gpt2'\n",
    "        elif model1 == 'clip':\n",
    "            pretrained_lm1 = 'openai/clip-vit-base-patch32'\n",
    "        elif model1 == 'igpt':\n",
    "            pretrained_lm1 = 'openai/imagegpt-small'\n",
    "\n",
    "        variant = {\n",
    "            'embed_dim': 128,\n",
    "            'n_layer': 3,\n",
    "            'n_head': 1,\n",
    "            'activation_function': 'relu',\n",
    "            'dropout': 0.2, # 0.1\n",
    "            'load_checkpoint': False if epoch1==0 else f'../checkpoints/{model1}_medium_hopper_666/model_{epoch1}.pt',\n",
    "            'seed': seed,\n",
    "            'outdir': f\"checkpoints/{model1}_{dataset_name}_{env_name}_{seed}\",\n",
    "            'env': env_name,\n",
    "            'dataset': dataset_name,\n",
    "            'model_type': 'dt',\n",
    "            'K': 20, # 2\n",
    "            'pct_traj': 1.0,\n",
    "            'batch_size': 100,  # 64\n",
    "            'num_eval_episodes': 100,\n",
    "            'max_iters': 40,\n",
    "            'num_steps_per_iter': 2500,\n",
    "            'pretrained_lm': pretrained_lm1,\n",
    "            'gpt_kmeans': None,\n",
    "            'kmeans_cache': None,\n",
    "            'frozen': False,\n",
    "            'extend_positions': False,\n",
    "            'share_input_output_proj': True\n",
    "        }\n",
    "\n",
    "        os.makedirs(variant[\"outdir\"], exist_ok=True)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        trajectories, sorted_inds, state_dim, act_dim, max_ep_len, state_mean, state_std, num_trajectories, p_sample, scale = prepare_data(variant)\n",
    "\n",
    "        K = variant[\"K\"]\n",
    "        batch_size = variant[\"batch_size\"]\n",
    "\n",
    "        states, actions, rewards, dones, rtg, timesteps, attention_mask = get_batch(batch_size, \n",
    "                                                                                    K,\n",
    "                                                                                    trajectories,\n",
    "                                                                                    sorted_inds,\n",
    "                                                                                    state_dim,\n",
    "                                                                                    act_dim,\n",
    "                                                                                    max_ep_len,\n",
    "                                                                                    state_mean,\n",
    "                                                                                    state_std,\n",
    "                                                                                    num_trajectories,\n",
    "                                                                                    p_sample,\n",
    "                                                                                    scale,\n",
    "                                                                                    device\n",
    "                                                                                   )\n",
    "        action_target = torch.clone(actions)\n",
    "\n",
    "        activation_list = []\n",
    "\n",
    "        for _ in range(2):\n",
    "\n",
    "            model = DecisionTransformer(\n",
    "                args=variant,\n",
    "                state_dim=state_dim,\n",
    "                act_dim=act_dim,\n",
    "                max_length=K,\n",
    "                max_ep_len=max_ep_len,\n",
    "                hidden_size=variant[\"embed_dim\"],\n",
    "                n_layer=variant[\"n_layer\"],\n",
    "                n_head=variant[\"n_head\"],\n",
    "                n_inner=4 * variant[\"embed_dim\"],\n",
    "                activation_function=variant[\"activation_function\"],\n",
    "                n_positions=1024,\n",
    "                resid_pdrop=variant[\"dropout\"],\n",
    "                attn_pdrop=0.1,\n",
    "            )\n",
    "            if variant[\"load_checkpoint\"]:\n",
    "                state_dict = torch.load(variant[\"load_checkpoint\"], map_location=torch.device('cpu'))\n",
    "                model.load_state_dict(state_dict)\n",
    "                print(f\"Loaded from {variant['load_checkpoint']}\")\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            activation = {}\n",
    "            def get_activation(name):\n",
    "                def hook(model, input, output):\n",
    "                    activation[name] = output.detach()\n",
    "                return hook\n",
    "\n",
    "            model.embed_timestep.register_forward_hook(get_activation(f'embed_timestep'))\n",
    "            model.embed_return.register_forward_hook(get_activation(f'embed_timestep'))\n",
    "            model.embed_state.register_forward_hook(get_activation(f'embed_state'))\n",
    "            model.embed_action.register_forward_hook(get_activation(f'embed_action'))\n",
    "            model.embed_ln.register_forward_hook(get_activation(f'embed_ln'))\n",
    "\n",
    "            state_preds, action_preds, reward_preds, all_embs = model.forward(\n",
    "                states,\n",
    "                actions,\n",
    "                rewards,\n",
    "                rtg[:, :-1],\n",
    "                timesteps,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "\n",
    "            if model2 == 'gpt2':\n",
    "                pretrained_lm2 = 'gpt2'\n",
    "            elif model2 == 'clip':\n",
    "                pretrained_lm2 = 'openai/clip-vit-base-patch32'\n",
    "            elif model2 == 'igpt':\n",
    "                pretrained_lm2 = 'openai/imagegpt-small'\n",
    "\n",
    "            activation_ordered = {}\n",
    "            module_name_list = [\n",
    "                'embed_timestep',\n",
    "                'embed_timestep',\n",
    "                'embed_state',\n",
    "                'embed_action',\n",
    "                'embed_ln'\n",
    "            ]\n",
    "            for module_id in range(5):\n",
    "                for module_name in module_name_list:\n",
    "                    activation_ordered[f'{module_name}'] = activation[f'{module_name}']\n",
    "\n",
    "            activation_list.append(activation_ordered)\n",
    "            \n",
    "            variant['load_checkpoint'] = checkpoint2 = False if epoch2==0 else f'../checkpoints/{model2}_medium_hopper_666/model_{epoch2}.pt'\n",
    "            variant['outdir'] =  f\"checkpoints/{model2}_{dataset_name}_{env_name}_{seed}\"\n",
    "            variant['pretrained_lm'] = pretrained_lm2\n",
    "\n",
    "        reward_state_action_list = ['action']\n",
    "        for reward_state_action in reward_state_action_list:\n",
    "            num_activation = len(activation_list[0].values())\n",
    "            cka_matrix = []\n",
    "            for key_1, act_1 in tqdm(activation_list[0].items()):\n",
    "                cka_list = []\n",
    "                for key_2, act_2 in activation_list[1].items():\n",
    "                    cka = compute_cka(act_1, act_2, reward_state_action)\n",
    "                    cka_list.append(cka)\n",
    "                cka_matrix.append(cka_list)\n",
    "            cka_matrix = np.array(cka_matrix)\n",
    "            \n",
    "        return cka_matrix\n",
    "\n",
    "            # np.save(f'results/cka_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.npy', cka_matrix)\n",
    "            \n",
    "            # plot_cka(cka_matrix, reward_state_action, model1, model2, env_name, dataset_name, seed, epoch1, epoch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d8ef52-f62e-4eb4-b5f1-f9530966564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: hopper medium\n",
      "2186 trajectories, 999906 timesteps found\n",
      "Average return: 1422.06, std: 378.95\n",
      "Max return: 3222.36, min: 315.87\n",
      "==================================================\n",
      "Loading from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type imagegpt to instantiate a model of type gpt2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at openai/imagegpt-small were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2Model were not initialized from the model checkpoint at openai/imagegpt-small and are newly initialized: ['transformer.h.22.ln_1.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.3.ln_1.bias', 'transformer.h.5.ln_2.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.5.ln_1.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.23.ln_2.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.9.ln_1.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.20.ln_2.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.12.ln_2.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.3.ln_2.bias', 'transformer.ln_f.bias', 'transformer.h.12.ln_1.bias', 'transformer.h.7.ln_2.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.0.ln_2.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.19.ln_2.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.17.ln_2.bias', 'transformer.h.20.ln_1.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.19.ln_1.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.13.ln_1.bias', 'transformer.h.13.ln_2.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.17.ln_1.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.23.ln_1.bias', 'transformer.h.9.ln_2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/shiro/miniforge3/envs/wikirl-gym/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type imagegpt to instantiate a model of type gpt2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at openai/imagegpt-small were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2Model were not initialized from the model checkpoint at openai/imagegpt-small and are newly initialized: ['transformer.h.22.ln_1.bias', 'transformer.h.4.ln_2.bias', 'transformer.h.3.ln_1.bias', 'transformer.h.5.ln_2.bias', 'transformer.h.21.ln_1.bias', 'transformer.h.14.ln_1.bias', 'transformer.h.5.ln_1.bias', 'transformer.h.2.ln_1.bias', 'transformer.h.23.ln_2.bias', 'transformer.h.4.ln_1.bias', 'transformer.h.8.ln_2.bias', 'transformer.h.9.ln_1.bias', 'transformer.h.6.ln_2.bias', 'transformer.h.20.ln_2.bias', 'transformer.h.10.ln_1.bias', 'transformer.h.12.ln_2.bias', 'transformer.h.16.ln_2.bias', 'transformer.h.11.ln_1.bias', 'transformer.h.3.ln_2.bias', 'transformer.ln_f.bias', 'transformer.h.12.ln_1.bias', 'transformer.h.7.ln_2.bias', 'transformer.h.18.ln_1.bias', 'transformer.h.14.ln_2.bias', 'transformer.h.15.ln_2.bias', 'transformer.h.0.ln_2.bias', 'transformer.h.7.ln_1.bias', 'transformer.h.18.ln_2.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.19.ln_2.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.22.ln_2.bias', 'transformer.h.8.ln_1.bias', 'transformer.h.21.ln_2.bias', 'transformer.h.17.ln_2.bias', 'transformer.h.20.ln_1.bias', 'transformer.h.15.ln_1.bias', 'transformer.h.6.ln_1.bias', 'transformer.h.19.ln_1.bias', 'transformer.h.10.ln_2.bias', 'transformer.h.13.ln_1.bias', 'transformer.h.13.ln_2.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.2.ln_2.bias', 'transformer.h.11.ln_2.bias', 'transformer.h.17.ln_1.bias', 'transformer.h.16.ln_1.bias', 'transformer.h.23.ln_1.bias', 'transformer.h.9.ln_2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from ../checkpoints/igpt_medium_hopper_666/model_40.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f320342b161d4600897beda62913853d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cka_matrix = run_cka(\n",
    "    seed=666,\n",
    "    model1='igpt',\n",
    "    model2='igpt',\n",
    "    epoch1=0,\n",
    "    epoch2=40,\n",
    "    env_name_list=['hopper'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b0e3d2a-0ee0-4774-b3d3-2a280085612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 2})\n",
    "\n",
    "plt.plot(np.diag(cka_matrix), color=(0.372, 0.537, 0.537))\n",
    "plt.scatter(np.arange(len(np.diag(cka_matrix))), np.diag(cka_matrix), color=(0.372, 0.537, 0.537))\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('CKA')\n",
    "plt.title(f'CKA per Layer: Action')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'figs/cka_plot_{epoch1}_{epoch2}_{model1}{model2}_{env_name}_{dataset_name}_{seed}_{reward_state_action}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300246ff-cee7-4734-882c-ee84dd9bca42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
