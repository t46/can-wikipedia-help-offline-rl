{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/shiro/research/projects/rl-nlp/can-wikipedia-help-offline-rl/code')\n",
    "\n",
    "from decision_transformer.evaluation.evaluate_episodes import (\n",
    "    evaluate_episode,\n",
    "    evaluate_episode_rtg,\n",
    ")\n",
    "from decision_transformer.models.decision_transformer import DecisionTransformer\n",
    "from decision_transformer.models.mlp_bc import MLPBCModel\n",
    "from decision_transformer.training.act_trainer import ActTrainer\n",
    "from decision_transformer.training.seq_trainer import SequenceTrainer\n",
    "\n",
    "from utils import get_optimizer\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: hopper medium\n",
      "2186 trajectories, 999906 timesteps found\n",
      "Average return: 1422.06, std: 378.95\n",
      "Max return: 3222.36, min: 315.87\n",
      "==================================================\n",
      "Loading from pretrained\n",
      "Loaded from ../checkpoints/dt_medium_hopper_666_K1/model_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiro/miniforge3/envs/wikirl-gym/lib/python3.8/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 666\n",
    "\n",
    "model_name = 'dt'\n",
    "\n",
    "env_name_list = ['hopper']\n",
    "\n",
    "layer = 11\n",
    "batchid = 0\n",
    "\n",
    "epoch = 40\n",
    "\n",
    "for env_name in env_name_list:\n",
    "# env_name = 'walker2d'\n",
    "    dataset_name = 'medium'\n",
    "\n",
    "    if model_name == 'gpt2':\n",
    "        pretrained_lm = 'gpt2'\n",
    "    elif model_name == 'clip':\n",
    "        pretrained_lm = 'openai/clip-vit-base-patch32'\n",
    "    elif model_name == 'igpt':\n",
    "        pretrained_lm = 'openai/imagegpt-small'\n",
    "\n",
    "    variant = {\n",
    "        'embed_dim': 128,\n",
    "        'n_layer': 3,\n",
    "        'n_head': 1,\n",
    "        'activation_function': 'relu',\n",
    "        'dropout': 0.2, # 0.1\n",
    "        'load_checkpoint': f'../checkpoints/{model_name}_medium_hopper_666_K1/model_{epoch}.pt',\n",
    "        'seed': seed,\n",
    "        'outdir': f\"checkpoints/{model_name}_{dataset_name}_{env_name}_{seed}\",\n",
    "        'env': env_name,\n",
    "        'dataset': dataset_name,\n",
    "        'model_type': 'dt',\n",
    "        'K': 1, # 2\n",
    "        'pct_traj': 1.0,\n",
    "        'batch_size': 100,  # 64\n",
    "        'num_eval_episodes': 100,\n",
    "        'max_iters': 40,\n",
    "        'num_steps_per_iter': 2500,\n",
    "        'pretrained_lm': pretrained_lm,\n",
    "        'gpt_kmeans': None,  # 1000 <-- メモリに乗らない\n",
    "        'kmeans_cache': None,  # 'kmeans_cache/gpt2_lm_1000.pt'\n",
    "        'frozen': False,\n",
    "        'extend_positions': False,\n",
    "        'share_input_output_proj': True\n",
    "    }\n",
    "\n",
    "    torch.manual_seed(variant[\"seed\"])\n",
    "    os.makedirs(variant[\"outdir\"], exist_ok=True)\n",
    "    # device = variant.get(\"device\", \"cuda\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    log_to_wandb = variant.get(\"log_to_wandb\", False)\n",
    "\n",
    "    env_name, dataset = variant[\"env\"], variant[\"dataset\"]\n",
    "    model_type = variant[\"model_type\"]\n",
    "    exp_prefix = 'gym-experiment'\n",
    "    group_name = f\"{exp_prefix}-{env_name}-{dataset}\"\n",
    "    exp_prefix = f\"{group_name}-{random.randint(int(1e5), int(1e6) - 1)}\"\n",
    "\n",
    "    if env_name == \"hopper\":\n",
    "        env = gym.make(\"Hopper-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [3600, 1800]  # evaluation conditioning targets\n",
    "        scale = 1000.0  # normalization for rewards/returns\n",
    "    elif env_name == \"halfcheetah\":\n",
    "        env = gym.make(\"HalfCheetah-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [12000, 6000]\n",
    "        scale = 1000.0\n",
    "    elif env_name == \"walker2d\":\n",
    "        env = gym.make(\"Walker2d-v3\")\n",
    "        max_ep_len = 1000\n",
    "        env_targets = [5000, 2500]\n",
    "        scale = 1000.0\n",
    "    elif env_name == \"reacher2d\":\n",
    "        from decision_transformer.envs.reacher_2d import Reacher2dEnv\n",
    "\n",
    "        env = Reacher2dEnv()\n",
    "        max_ep_len = 100\n",
    "        env_targets = [76, 40]\n",
    "        scale = 10.0\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if model_type == \"bc\":\n",
    "        env_targets = env_targets[\n",
    "            :1\n",
    "        ]  # since BC ignores target, no need for different evaluations\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    # load dataset\n",
    "    dataset_path = f\"../data/{env_name}-{dataset}-v2.pkl\"\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        trajectories = pickle.load(f)\n",
    "\n",
    "    # save all path information into separate lists\n",
    "    mode = variant.get(\"mode\", \"normal\")\n",
    "    states, traj_lens, returns = [], [], []\n",
    "    for path in trajectories:\n",
    "        if mode == \"delayed\":  # delayed: all rewards moved to end of trajectory\n",
    "            path[\"rewards\"][-1] = path[\"rewards\"].sum()\n",
    "            path[\"rewards\"][:-1] = 0.0\n",
    "        states.append(path[\"observations\"])\n",
    "        traj_lens.append(len(path[\"observations\"]))\n",
    "        returns.append(path[\"rewards\"].sum())\n",
    "    traj_lens, returns = np.array(traj_lens), np.array(returns)\n",
    "\n",
    "    # used for input normalization\n",
    "    states = np.concatenate(states, axis=0)\n",
    "    state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "    num_timesteps = sum(traj_lens)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Starting new experiment: {env_name} {dataset}\")\n",
    "    print(f\"{len(traj_lens)} trajectories, {num_timesteps} timesteps found\")\n",
    "    print(f\"Average return: {np.mean(returns):.2f}, std: {np.std(returns):.2f}\")\n",
    "    print(f\"Max return: {np.max(returns):.2f}, min: {np.min(returns):.2f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    K = variant[\"K\"]\n",
    "    batch_size = variant[\"batch_size\"]\n",
    "    num_eval_episodes = variant[\"num_eval_episodes\"]\n",
    "    pct_traj = variant.get(\"pct_traj\", 1.0)\n",
    "\n",
    "    # only train on top pct_traj trajectories (for %BC experiment)\n",
    "    num_timesteps = max(int(pct_traj * num_timesteps), 1)\n",
    "    sorted_inds = np.argsort(returns)  # lowest to highest\n",
    "    num_trajectories = 1\n",
    "    timesteps = traj_lens[sorted_inds[-1]]\n",
    "    ind = len(trajectories) - 2\n",
    "    while ind >= 0 and timesteps + traj_lens[sorted_inds[ind]] < num_timesteps:\n",
    "        timesteps += traj_lens[sorted_inds[ind]]\n",
    "        num_trajectories += 1\n",
    "        ind -= 1\n",
    "    sorted_inds = sorted_inds[-num_trajectories:]\n",
    "\n",
    "    # used to reweight sampling so we sample according to timesteps instead of trajectories\n",
    "    p_sample = traj_lens[sorted_inds] / sum(traj_lens[sorted_inds])\n",
    "\n",
    "    def discount_cumsum(x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def get_batch(batch_size=256, max_len=K):\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(num_trajectories),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        for i in range(batch_size):\n",
    "            traj = trajectories[int(sorted_inds[batch_inds[i]])]\n",
    "            si = random.randint(0, traj[\"rewards\"].shape[0] - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(traj[\"observations\"][si : si + max_len].reshape(1, -1, state_dim))\n",
    "            a.append(traj[\"actions\"][si : si + max_len].reshape(1, -1, act_dim))\n",
    "            r.append(traj[\"rewards\"][si : si + max_len].reshape(1, -1, 1))\n",
    "            if \"terminals\" in traj:\n",
    "                d.append(traj[\"terminals\"][si : si + max_len].reshape(1, -1))\n",
    "            else:\n",
    "                d.append(traj[\"dones\"][si : si + max_len].reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= max_ep_len] = (\n",
    "                max_ep_len - 1\n",
    "            )  # padding cutoff\n",
    "            rtg.append(\n",
    "                discount_cumsum(traj[\"rewards\"][si:], gamma=1.0)[\n",
    "                    : s[-1].shape[1] + 1\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] <= s[-1].shape[1]:\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate(\n",
    "                [np.zeros((1, max_len - tlen, state_dim)), s[-1]], axis=1\n",
    "            )\n",
    "            s[-1] = (s[-1] - state_mean) / state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, max_len - tlen, act_dim)) * -10.0, a[-1]], axis=1\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = (\n",
    "                np.concatenate([np.zeros((1, max_len - tlen, 1)), rtg[-1]], axis=1)\n",
    "                / scale\n",
    "            )\n",
    "            timesteps[-1] = np.concatenate(\n",
    "                [np.zeros((1, max_len - tlen)), timesteps[-1]], axis=1\n",
    "            )\n",
    "            mask.append(\n",
    "                np.concatenate(\n",
    "                    [np.zeros((1, max_len - tlen)), np.ones((1, tlen))], axis=1\n",
    "                )\n",
    "            )\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).to(\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).to(\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).to(\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0)).to(\n",
    "            dtype=torch.long, device=device\n",
    "        )\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).to(\n",
    "            dtype=torch.float32, device=device\n",
    "        )\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).to(\n",
    "            dtype=torch.long, device=device\n",
    "        )\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).to(device=device)\n",
    "\n",
    "        return s, a, r, d, rtg, timesteps, mask\n",
    "\n",
    "    (\n",
    "        states,\n",
    "        actions,\n",
    "        rewards,\n",
    "        dones,\n",
    "        rtg,\n",
    "        timesteps,\n",
    "        attention_mask,\n",
    "    ) = get_batch(batch_size)\n",
    "    action_target = torch.clone(actions)\n",
    "    \n",
    "    model = DecisionTransformer(\n",
    "        args=variant,\n",
    "        state_dim=state_dim,\n",
    "        act_dim=act_dim,\n",
    "        max_length=K,\n",
    "        max_ep_len=max_ep_len,\n",
    "        hidden_size=variant[\"embed_dim\"],\n",
    "        n_layer=variant[\"n_layer\"],\n",
    "        n_head=variant[\"n_head\"],\n",
    "        n_inner=4 * variant[\"embed_dim\"],\n",
    "        activation_function=variant[\"activation_function\"],\n",
    "        n_positions=1024,\n",
    "        resid_pdrop=variant[\"dropout\"],\n",
    "        attn_pdrop=0.1,\n",
    "    )\n",
    "    if variant[\"load_checkpoint\"]:\n",
    "        state_dict = torch.load(variant[\"load_checkpoint\"], map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded from {variant['load_checkpoint']}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        model.transformer.h[block_id].ln_1.register_forward_hook(get_activation(f'{block_id}.ln_1'))\n",
    "        model.transformer.h[block_id].attn.c_attn.register_forward_hook(get_activation(f'{block_id}.attn.c_attn'))\n",
    "        model.transformer.h[block_id].attn.c_proj.register_forward_hook(get_activation(f'{block_id}.attn.c_proj'))\n",
    "        model.transformer.h[block_id].attn.attn_dropout.register_forward_hook(get_activation(f'{block_id}.attn.attn_dropout'))\n",
    "        model.transformer.h[block_id].attn.resid_dropout.register_forward_hook(get_activation(f'{block_id}.attn.resid_dropout'))\n",
    "        model.transformer.h[block_id].ln_2.register_forward_hook(get_activation(f'{block_id}.ln_2'))\n",
    "        model.transformer.h[block_id].mlp.c_fc.register_forward_hook(get_activation(f'{block_id}.mlp.c_fc'))\n",
    "        model.transformer.h[block_id].mlp.c_proj.register_forward_hook(get_activation(f'{block_id}.mlp.c_proj'))\n",
    "        model.transformer.h[block_id].mlp.act.register_forward_hook(get_activation(f'{block_id}.mlp.act'))\n",
    "        model.transformer.h[block_id].mlp.dropout.register_forward_hook(get_activation(f'{block_id}.mlp.dropout'))\n",
    "\n",
    "    state_preds, action_preds, reward_preds, all_embs = model.forward(\n",
    "        states,\n",
    "        actions,\n",
    "        rewards,\n",
    "        rtg[:, :-1],\n",
    "        timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "    )\n",
    "\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\", 1.5, {\"lines.linewidth\": 2})\n",
    "    \n",
    "    activation_ordered = {}\n",
    "    block_name_list = [\n",
    "        'ln_1',\n",
    "        'attn.c_attn',\n",
    "        'attn.c_proj',\n",
    "        'attn.resid_dropout',\n",
    "        'ln_2',\n",
    "        'mlp.c_fc',\n",
    "        'mlp.c_proj',\n",
    "        'mlp.act',\n",
    "        'mlp.dropout'\n",
    "    ]\n",
    "    for block_id in range(len(model.transformer.h)):\n",
    "        for block_name in block_name_list:\n",
    "            activation_ordered[f'{block_id}.{block_name}'] = activation[f'{block_id}.{block_name}']\n",
    "\n",
    "\n",
    "    query = activation_ordered[f'{layer}.attn.c_attn'][batchid, :, :768]  # 0, 5, 11\n",
    "    key = activation_ordered[f'{layer}.attn.c_attn'][batchid, :, 768: 1536]  # 0, 5, 11\n",
    "\n",
    "    att_weight_mat = torch.tril(torch.softmax(torch.matmul(query, key.t()) / np.sqrt(768), dim=1))\n",
    "    \n",
    "    np.save(f'results/attention_K1_{epoch}_{model_name}_{env_name}_{dataset_name}_{seed}_layer{layer}_batchid{batchid}.npy', att_weight_mat)\n",
    "\n",
    "    # ax = sns.heatmap(att_weight_mat, vmin=0, vmax=0.03)\n",
    "    ax = sns.heatmap(att_weight_mat, vmin=0, vmax=1, square=True)\n",
    "    # ax.axis('equal')\n",
    "    # plt.ylim(0, K * 3)\n",
    "    # plt.xlim(0, K * 3)\n",
    "    plt.xlabel('Key')\n",
    "    plt.ylabel('Query')\n",
    "    plt.title(f'Attention Weight: {model_name.upper()}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figs/attention_K1_{epoch}_{model_name}_{env_name}_{dataset_name}_{seed}_layer{layer}_batchid{batchid}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07f70ea1113ee523b3efee6307f7578bdf4830bd47c6db9199b4b48d8758cb04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('wikirl-gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
